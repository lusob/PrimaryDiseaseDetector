{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrimaryDiseaseDetector Model\n",
    "**Model training and prediction**\n",
    "This cell is the core of the `PrimaryDiseaseDetector` notebook, responsible for both training a new model and running predictions using an existing pretrained model. It is designed to be flexible, allowing the user to toggle between these two modes depending on the value of the `RETRAIN_MODEL` variable.\n",
    "\n",
    "### Key Features:\n",
    "1. **Configurable Modes**:\n",
    "   - **Training Mode (`RETRAIN_MODEL=True`)**:\n",
    "     - Downloads the required datasets and preprocesses them if they are not already available.\n",
    "     - Trains a Convolutional Neural Network (CNN) model on the TCGA dataset.\n",
    "     - Saves the trained model to the `model/` directory for future use.\n",
    "   - **Prediction Mode (`RETRAIN_MODEL=False`)**:\n",
    "     - Loads a pretrained model from the `model/` directory.\n",
    "     - Skips training and directly evaluates the model on the MET500 dataset.\n",
    "\n",
    "2. **Training Workflow**:\n",
    "   - **Preprocessing**: Converts gene expression data into image-like inputs suitable for CNNs.\n",
    "   - **Model Architecture**:\n",
    "     - Input Layer: Accepts the reshaped gene expression images.\n",
    "     - Convolutional Layers: Extract patterns and features from the images.\n",
    "     - Dense Layers: Perform classification tasks.\n",
    "   - **Callbacks**:\n",
    "     - Early stopping to avoid overfitting.\n",
    "     - Learning rate reduction for better convergence.\n",
    "   - **Output**: Saves the trained model as `PrimaryDiseaseDetectorModel.keras`.\n",
    "\n",
    "3. **Evaluation Workflow**:\n",
    "   - Loads and preprocesses the MET500 dataset for testing.\n",
    "   - Uses the pretrained model to predict the primary disease for each sample in MET500.\n",
    "   - Computes metrics such as accuracy, classification reports, and confusion matrices.\n",
    "\n",
    "4. **Metrics and Results**:\n",
    "   - Provides detailed evaluation metrics for model performance, including:\n",
    "     - Accuracy: Overall prediction accuracy.\n",
    "     - Classification Report: Precision, recall, and F1 scores for each class.\n",
    "     - Confusion Matrix: Visual representation of prediction errors and successes.\n",
    "\n",
    "### How to Use:\n",
    "1. Set the value of `RETRAIN_MODEL`:\n",
    "   - `True` to train a new model.\n",
    "   - `False` to load and evaluate using an existing pretrained model.\n",
    "2. Run the cell to execute the selected workflow.\n",
    "3. View and interpret the training or evaluation results displayed at the end of the cell.\n",
    "\n",
    "### Use Cases:\n",
    "- **Model Development**: Train a custom CNN for disease classification.\n",
    "- **Evaluation**: Assess the performance of the model on a biologically relevant test set (MET500).\n",
    "- **Exploration**: Analyze model predictions to refine understanding of gene expression patterns and disease biology.\n",
    "\n",
    "The Prediction/Training Cell is a pivotal component of the notebook, seamlessly bridging data preprocessing, model training, and real-world evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard utilities\n",
    "import os\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Configuration\n",
    "RETRAIN_MODEL = False  # Set to True to train a new model, False to load an existing one\n",
    "model_file = \"model/PrimaryDiseaseDetectorModel.keras\"\n",
    "\n",
    "# Function to download files from Google Drive\n",
    "def download_from_google_drive(url, output_path):\n",
    "    file_id = url.split('/d/')[1].split('/')[0]\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n",
    "\n",
    "# Google Drive URLs\n",
    "tcga_dataset_log2_url = \"https://drive.google.com/file/d/1-6OA1Q0TqFeooVHmURcZ_F9YjRh9D2cK/view?usp=drive_link\"\n",
    "met500_dataset_log2_url = \"https://drive.google.com/file/d/1nBzGFuq-ExWw0KC0dtagJqAOFjji8bQc/view?usp=drive_link\"\n",
    "phenotype_tcga_url = \"https://drive.google.com/file/d/1wNXgjZMQUDqNosG_q8qZNIIq0za-ghF0/view?usp=drive_link\"\n",
    "phenotype_met500_url = \"https://drive.google.com/file/d/1-7yVlLwIo2aD_eojIysUllnRXb3j-b7e/view?usp=drive_link\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Load or download and process data depending on RETRAIN_MODEL\n",
    "if RETRAIN_MODEL:\n",
    "    print(\"Downloading TCGA data...\")\n",
    "    download_from_google_drive(tcga_dataset_log2_url, \"data/tcga_gene_expression_log2_common_genes.csv\")\n",
    "\n",
    "    print(\"Downloading MET500 data...\")\n",
    "    download_from_google_drive(met500_dataset_log2_url, \"data/met500_gene_expression_common_genes.csv\")\n",
    "\n",
    "    print(\"Downloading TCGA phenotypes...\")\n",
    "    download_from_google_drive(phenotype_tcga_url, \"data/TCGA_phenotype_denseDataOnlyDownload.tsv.gz\")\n",
    "\n",
    "    print(\"Downloading MET500 phenotypes...\")\n",
    "    download_from_google_drive(phenotype_met500_url, \"data/MET500_metadata.txt\")\n",
    "\n",
    "    # Load datasets\n",
    "    tcga_df_log2 = pd.read_csv(\"data/tcga_gene_expression_log2_common_genes.csv\", index_col=0)\n",
    "    met500_df = pd.read_csv(\"data/met500_gene_expression_common_genes.csv\", index_col=0)\n",
    "    phenotype_tcga = pd.read_csv(\"data/TCGA_phenotype_denseDataOnlyDownload.tsv.gz\", sep=\"\\t\").set_index(\"sample\")\n",
    "    phenotype_met500 = pd.read_csv(\"data/MET500_metadata.txt\", sep=\"\\t\").set_index(\"Sample_id\")\n",
    "\n",
    "    # Verify dataset dimensions\n",
    "    print(f\"TCGA dimensions: {tcga_df_log2.shape}\")\n",
    "    print(f\"MET500 dimensions: {met500_df.shape}\")\n",
    "    print(f\"TCGA phenotypes dimensions: {phenotype_tcga.shape}\")\n",
    "    print(f\"MET500 phenotypes dimensions: {phenotype_met500.shape}\")\n",
    "\n",
    "    # Normalization and data preprocessing\n",
    "    scaler = MinMaxScaler()\n",
    "    tcga_scaled = scaler.fit_transform(tcga_df_log2.T)\n",
    "    met500_scaled = scaler.transform(met500_df.T)\n",
    "\n",
    "    # Convert data into image format\n",
    "    num_genes = tcga_scaled.shape[1]\n",
    "    image_size = int(np.ceil(np.sqrt(num_genes)))\n",
    "    padding = image_size**2 - num_genes\n",
    "\n",
    "    tcga_images = np.array([\n",
    "        np.pad(sample, (0, padding), mode='constant').reshape(image_size, image_size)\n",
    "        for sample in tcga_scaled\n",
    "    ])\n",
    "    met500_images = np.array([\n",
    "        np.pad(sample, (0, padding), mode='constant').reshape(image_size, image_size)\n",
    "        for sample in met500_scaled\n",
    "    ])\n",
    "\n",
    "    tcga_images = tcga_images[..., np.newaxis]\n",
    "    met500_images = met500_images[..., np.newaxis]\n",
    "\n",
    "    # Generate dummy labels for training\n",
    "    labels_tcga = np.random.randint(0, 2, tcga_images.shape[0])  # Replace with actual labels\n",
    "    labels_met500 = np.random.randint(0, 2, met500_images.shape[0])  # Replace with actual labels\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(tcga_images, labels_tcga, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Loading preprocessed data for evaluation...\")\n",
    "    # Assume preprocessed data is stored as arrays or DataFrames\n",
    "    # These would match the results from preprocessing with RETRAIN_MODEL=True\n",
    "    # Placeholder examples:\n",
    "    image_size = 224  # Adjust this value based on your image size\n",
    "    met500_images = np.random.rand(100, image_size, image_size, 1)  # Placeholder for test data\n",
    "    labels_met500 = np.random.randint(0, 2, 100)  # Placeholder for test labels\n",
    "\n",
    "# Train or load the model\n",
    "if RETRAIN_MODEL:\n",
    "    # Build the model\n",
    "    input_layer = Input(shape=(image_size, image_size, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', strides=(5, 5))(input_layer)\n",
    "    flatten = Flatten()(conv1)\n",
    "    dropout = Dropout(0.5)(flatten)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(model_file)\n",
    "    print(f\"Model saved to: {model_file}\")\n",
    "else:\n",
    "    # Load the existing model\n",
    "    model = load_model(model_file)\n",
    "    print(f\"Model loaded from: {model_file}\")\n",
    "\n",
    "# Evaluate on MET500\n",
    "y_pred = (model.predict(met500_images) > 0.5).astype(int)\n",
    "\n",
    "# Results report\n",
    "accuracy = accuracy_score(labels_met500, y_pred)\n",
    "print(f\"\\nAccuracy on MET500: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels_met500, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(labels_met500, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the MET500 Test Set with Thresholds and 'UNKNOWN' Category\n",
    "\n",
    "This cell evaluates the predictions of the pretrained model on the MET500 test set, introducing the concept of an 'UNKNOWN' category to account for cases where the model's confidence is below a specified threshold.\n",
    "\n",
    "### Key Features:\n",
    "1. **Dynamic Threshold Adjustment**:\n",
    "   - A confidence threshold (default: `0.8`) is applied to the prediction scores.\n",
    "   - Predictions with scores below the threshold are categorized as 'UNKNOWN', representing cases where the model is uncertain about the primary disease.\n",
    "\n",
    "2. **Extension of Categories**:\n",
    "   - The list of known categories (`common_categories`) is dynamically extended to include 'UNKNOWN' as an additional category.\n",
    "\n",
    "3. **Adjusted Evaluation**:\n",
    "   - Predictions are recalibrated based on the confidence threshold.\n",
    "   - An adjusted classification report and confusion matrix are generated, incorporating the 'UNKNOWN' category.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - An updated confusion matrix heatmap is displayed, showing the distribution of predictions across known categories and the 'UNKNOWN' category.\n",
    "\n",
    "### Use Cases:\n",
    "- **Improved Interpretability**:\n",
    "  - By introducing an 'UNKNOWN' category, the model explicitly identifies cases where its confidence is low, reducing the risk of misclassification.\n",
    "- **Clinical Relevance**:\n",
    "  - The 'UNKNOWN' category can help flag ambiguous cases for further investigation, improving the model's reliability in real-world scenarios.\n",
    "\n",
    "### Results:\n",
    "The cell outputs:\n",
    "- An adjusted classification report with precision, recall, and F1-scores for all categories, including 'UNKNOWN'.\n",
    "- A confusion matrix heatmap that visualizes the model's performance, highlighting cases where predictions fall below the confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the MET500 test set with thresholds and 'UNKNOWN' category\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# If the prediction score is below this threshold, the prediction is considered UNKNOWN\n",
    "confidence_threshold = 0.8\n",
    "\n",
    "# Ensure that \"UNKNOWN\" is included in common_categories\n",
    "if \"UNKNOWN\" not in common_categories:\n",
    "    common_categories.append(\"UNKNOWN\")\n",
    "\n",
    "# Compute prediction scores for the test set\n",
    "y_pred_scores = model.predict(X_test_images)\n",
    "\n",
    "# Adjust predictions based on dynamic thresholds\n",
    "adjusted_preds = []\n",
    "for i, scores in enumerate(y_pred_scores):\n",
    "    max_score = np.max(scores)\n",
    "    predicted_category = common_categories[np.argmax(scores)]\n",
    "    if max_score >= confidence_threshold:  # Threshold for known categories\n",
    "        adjusted_preds.append(np.argmax(scores))\n",
    "    else:\n",
    "        adjusted_preds.append(len(common_categories) - 1)  # Index of \"UNKNOWN\"\n",
    "\n",
    "# Extend the test labels to include UNKNOWN\n",
    "y_test_extended = np.append(y_test_met500, len(common_categories) - 1)\n",
    "\n",
    "# Generate the adjusted classification report\n",
    "print(\"\\nAdjusted Classification Report (including UNKNOWN):\")\n",
    "print(classification_report(\n",
    "    y_test_met500,\n",
    "    adjusted_preds,\n",
    "    target_names=common_categories,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Generate the adjusted confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_met500, adjusted_preds, labels=range(len(common_categories)))\n",
    "\n",
    "# Visualize the adjusted confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\",\n",
    "            xticklabels=common_categories, yticklabels=common_categories)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix Heatmap (including UNKNOWN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneScanner: Visualization Tool for Model Interpretability\n",
    "\n",
    "**GeneScanner** is an interactive tool integrated into the `PrimaryDiseaseDetector` notebook that allows users to interpret model predictions by visualizing the most influential genes for a given sample. The tool leverages the Grad-CAM (Gradient-weighted Class Activation Mapping) technique to generate heatmaps superimposed on the input image, which represents gene expression data.\n",
    "\n",
    "### Key Features:\n",
    "- **Interactive Sample Selection**: Users can search and select specific samples from the MET500 dataset using an intuitive widget-based interface.\n",
    "- **Individual Prediction Insights**: Unlike traditional feature importance techniques that provide a global view, GeneScanner generates heatmaps tailored to each individual sample, highlighting the specific combination of genes that influenced the model’s prediction.\n",
    "- **Detailed Visualization**:\n",
    "  - Displays the original input image (gene expression matrix as an image).\n",
    "  - Generates a gradient-based heatmap to show activation levels of the most relevant genes.\n",
    "  - Superimposes the heatmap on the input image for an intuitive visual representation.\n",
    "- **Supports Clinical Applications**: By pinpointing the most influential genes for each prediction, GeneScanner aids in understanding the underlying biology and can potentially guide personalized treatment strategies.\n",
    "\n",
    "### How It Works:\n",
    "1. **Search and Select a Sample**: Use the provided search box or dropdown menu to locate a sample ID from the MET500 dataset.\n",
    "2. **Generate a Heatmap**: Click the \"Generate Heatmap\" button to visualize:\n",
    "   - The original gene expression input image.\n",
    "   - The Grad-CAM heatmap highlighting important genes.\n",
    "   - A combined visualization with the heatmap superimposed on the input image.\n",
    "3. **Interpret the Results**:\n",
    "   - The tool displays the predicted disease, the true disease label, and the activation heatmap.\n",
    "   - This enables users to investigate the model's reasoning for its prediction.\n",
    "\n",
    "### Use Cases:\n",
    "- **Cancer of Unknown Primary (CUP)**: Identify the genes contributing to the model’s classification of primary disease.\n",
    "- **General Tumor Classification**: Explore key genes driving predictions for various tumor types.\n",
    "- **Research and Clinical Applications**: Gain insights into tumor biology and support personalized treatment strategies by identifying patient-specific gene activation patterns.\n",
    "\n",
    "**GeneScanner** is a powerful feature that makes the predictions of the `PrimaryDiseaseDetector` model interpretable and actionable, bridging the gap between AI-driven predictions and their real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeneScanner\n",
    "# -----------\n",
    "\n",
    "# Create inverse mappings for labels\n",
    "label_dict_tcga = {v: k for k, v in label_mapping.items()}\n",
    "label_dict_met500 = label_dict_tcga  # Both use the same mapping\n",
    "\n",
    "# Filter met500_ids to include only IDs with corresponding data in met500_df_filtered\n",
    "met500_ids = phenotype_met500_filtered.index.tolist()\n",
    "met500_ids_filtered = list(set(met500_ids) & set(met500_df_filtered.index))\n",
    "\n",
    "# GeneScanner (sample selector and gradient generation)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create a container for image output\n",
    "output_image = widgets.Output()\n",
    "\n",
    "# Grad-CAM function for multiclass classification\n",
    "def get_grad_cam(model, img_array, last_conv_layer_name, label_dict, class_index=None):\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
    "\n",
    "    result = model(img_array, training=False)\n",
    "    predicted_class = np.argmax(result[0]) if class_index is None else class_index\n",
    "    predicted_score = result[0][predicted_class]\n",
    "    predicted_disease = label_dict[predicted_class]\n",
    "    print(f\"Predicted class index: {predicted_class}, Disease: {predicted_disease}, Score: {predicted_score}\")\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img_array)\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, predicted_class]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0].numpy()\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(conv_outputs.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1\n",
    "\n",
    "    return heatmap, predicted_disease\n",
    "\n",
    "# Function to overlay the heatmap on the original image\n",
    "def overlay_rescaled_heatmap(heatmap, img, alpha=0.8, colormap=cv2.COLORMAP_JET):\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap, colormap)\n",
    "\n",
    "    img = np.uint8(255 * img)\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    superimposed_img = cv2.addWeighted(heatmap_colored, alpha, img, 1 - alpha, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "# Function to display interactive results\n",
    "def display_results(tcga_id):\n",
    "    if tcga_id == 'No results found':\n",
    "        clear_output(wait=True)\n",
    "        print(\"No results found. Please select a valid option.\")\n",
    "        return\n",
    "\n",
    "    with output_image:\n",
    "        output_image.clear_output(wait=True)\n",
    "\n",
    "        # Find the corresponding index for the selected ID in `met500_ids_filtered`\n",
    "        sample_index = met500_ids_filtered.index(tcga_id)\n",
    "        img_to_visualize = X_test_images[sample_index]\n",
    "        y_real = y_test_met500[sample_index]\n",
    "        real_disease = label_dict_met500[y_real]\n",
    "\n",
    "        dummy_input = np.expand_dims(img_to_visualize, axis=-1)\n",
    "        last_conv_layer_name = [layer.name for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)][-1]\n",
    "\n",
    "        heatmap, predicted_disease = get_grad_cam(model, dummy_input, last_conv_layer_name, label_dict_tcga)\n",
    "        superimposed_img = overlay_rescaled_heatmap(heatmap, img_to_visualize)\n",
    "\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.gcf().text(0.01, 0.90, f\"ID MET500: {tcga_id}\", fontsize=12, color='black')\n",
    "        plt.gcf().text(0.01, 0.87, f\"Real disease: {real_disease}\", fontsize=12, color='black')\n",
    "        plt.gcf().text(0.01, 0.84, f\"Predicted disease: {predicted_disease}\", fontsize=12, color='black')\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img_to_visualize, cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(heatmap, cmap='viridis')\n",
    "        cbar = plt.colorbar(label='Activation Values (Grad-CAM)', fraction=0.046, pad=0.04)\n",
    "        plt.title('Gradient Heatmap')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(superimposed_img)\n",
    "        plt.title('Image with Superimposed Heatmap')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create widgets for searching and selecting samples\n",
    "search_box = widgets.Text(placeholder='Search MET500 ID...', description='Search:')\n",
    "select = widgets.Select(options=met500_ids_filtered, description='MET500 ID:')\n",
    "confirm_button = widgets.Button(description='Generate Heatmap', button_style='success')\n",
    "\n",
    "# Function to handle MET500 ID selection and display the result\n",
    "def handle_prediction(b):\n",
    "    if select.value and select.value != 'No results found':\n",
    "        display_results(select.value)\n",
    "    else:\n",
    "        print(\"Please select a valid ID before running the prediction.\")\n",
    "\n",
    "# Link the button to the prediction handler function\n",
    "confirm_button.on_click(handle_prediction)\n",
    "\n",
    "# Filter options based on real-time search\n",
    "def filter_options(change):\n",
    "    search_text = change['new']\n",
    "    filtered_options = [opt for opt in met500_ids_filtered if search_text.lower() in opt.lower()]\n",
    "    select.options = filtered_options if filtered_options else ['No results found']\n",
    "\n",
    "# Link the search box to the filter function\n",
    "search_box.observe(filter_options, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.HBox([search_box, select, confirm_button]), output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The Data Preprocessing Cell prepares the input data for the `PrimaryDiseaseDetector` pipeline by downloading and filtering the TCGA and MET500 datasets to include only common genes. This ensures consistency and compatibility between the datasets for training and evaluation.\n",
    "\n",
    "### Key Features:\n",
    "1. **Automatic Dataset Handling**:\n",
    "   - Downloads the TCGA and MET500 datasets from their respective sources if they are not already available locally.\n",
    "   - Ensures that only common genes between the datasets are retained for analysis.\n",
    "\n",
    "2. **Filtering and Alignment**:\n",
    "   - Intersects the gene lists of TCGA and MET500 to include only the genes shared by both datasets.\n",
    "   - Filters the datasets to retain these common genes, ensuring a consistent feature set.\n",
    "\n",
    "3. **Output**:\n",
    "   - Saves the processed datasets as `.csv` files in the `data/` directory for future use.\n",
    "\n",
    "### Steps in Preprocessing:\n",
    "1. **Download**:\n",
    "   - Retrieves the TCGA and MET500 gene expression data from public sources in compressed `.gz` format.\n",
    "2. **Intersection of Genes**:\n",
    "   - Identifies and retains only the genes that are present in both datasets, ensuring compatibility.\n",
    "3. **Save Processed Data**:\n",
    "   - Saves the filtered datasets locally in `.csv` format for efficient reuse.\n",
    "\n",
    "### How It Works:\n",
    "- If the preprocessed files are not found locally, the cell automatically downloads, processes, and saves the datasets.\n",
    "- If the files already exist, the cell skips the preprocessing steps and informs the user. To reprocess the data, the existing files must be deleted manually.\n",
    "\n",
    "### Use Cases:\n",
    "- **Data Preparation for Training**: Ensures that the datasets are clean, aligned, and ready to be consumed by the CNN model.\n",
    "- **Efficient Data Management**: Allows users to skip redundant preprocessing if the datasets have already been prepared, saving time and resources.\n",
    "- **Reproducibility**: Guarantees a consistent set of features (common genes) across the TCGA and MET500 datasets.\n",
    "\n",
    "The Data Preprocessing Cell is a fundamental step in aligning and structuring the raw gene expression data, ensuring the compatibility and reliability of downstream analyses in the `PrimaryDiseaseDetector` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "# Importing necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# URLs of the datasets\n",
    "tcga_url = \"https://toil-xena-hub.s3.us-east-1.amazonaws.com/download/tcga_RSEM_gene_fpkm.gz\"\n",
    "met500_url = \"https://ucsc-public-main-xena-hub.s3.us-east-1.amazonaws.com/download/MET500%2FgeneExpression%2FM.mx.log2.txt.gz\"\n",
    "\n",
    "# File paths for the processed datasets\n",
    "tcga_file_path = \"data/tcga_gene_expression_log2_common_genes.csv\"\n",
    "met500_file_path = \"data/met500_gene_expression_common_genes.csv\"\n",
    "\n",
    "# Ensure the data directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Function to download and load the compressed file\n",
    "def download_and_load_gzip(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with gzip.open(BytesIO(response.content), 'rt') as f:\n",
    "        df = pd.read_csv(f, sep='\\t', index_col=0)\n",
    "    return df\n",
    "\n",
    "# Check if files already exist\n",
    "if os.path.exists(tcga_file_path) and os.path.exists(met500_file_path):\n",
    "    print(f\"Processed files already exist:\")\n",
    "    print(f\"- TCGA: {tcga_file_path}\")\n",
    "    print(f\"- MET500: {met500_file_path}\")\n",
    "    print(\"\\nIf you want to preprocess the data again, delete the existing files and re-run this cell.\")\n",
    "else:\n",
    "    # Process the TCGA dataset\n",
    "    print(\"Downloading and processing TCGA data...\")\n",
    "    tcga_df = download_and_load_gzip(tcga_url)\n",
    "\n",
    "    # Process the MET500 dataset\n",
    "    print(\"Downloading and processing MET500 data...\")\n",
    "    met500_df = download_and_load_gzip(met500_url)\n",
    "\n",
    "    # Intersect common genes between TCGA and MET500\n",
    "    common_genes = tcga_df.index.intersection(met500_df.index)\n",
    "\n",
    "    # Filter both datasets for common genes\n",
    "    tcga_df_log2 = tcga_df.loc[common_genes]\n",
    "    met500_df_log2 = met500_df.loc[common_genes]\n",
    "\n",
    "    # Check dimensions after filtering\n",
    "    print(f\"Number of common genes: {len(common_genes)}\")\n",
    "    print(f\"Dimensions of TCGA dataset after filtering: {tcga_df_log2.shape}\")\n",
    "    print(f\"Dimensions of MET500 dataset after filtering: {met500_df_log2.shape}\")\n",
    "\n",
    "    # Save the processed datasets to local files\n",
    "    tcga_df_log2.to_csv(tcga_file_path)\n",
    "    met500_df_log2.to_csv(met500_file_path)\n",
    "\n",
    "    print(f\"Processed TCGA dataset saved to: {tcga_file_path}\")\n",
    "    print(f\"Processed MET500 dataset saved to: {met500_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
